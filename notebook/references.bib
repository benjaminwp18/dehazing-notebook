
@inproceedings{carlevaris-bianco_initial_2010,
	title = {Initial results in underwater single image dehazing},
	url = {https://ieeexplore.ieee.org/document/5664428},
	doi = {10.1109/OCEANS.2010.5664428},
	abstract = {As light is transmitted from subject to observer it is absorbed and scattered by the medium it passes through. In mediums with large suspended particles, such as fog or turbid water, the effect of scattering can drastically decrease the quality of images. In this paper we present an algorithm for removing the effects of light scattering, referred to as dehazing, in underwater images. Our key contribution is to propose a simple, yet effective, prior that exploits the strong difference in attenuation between the three image color channels in water to estimate the depth of the scene. We then use this estimate to reduce the spatially varying effect of haze in the image. Our method works with a single image and does not require any specialized hardware or prior knowledge of the scene. As a by-product of the dehazing process, an up-to-scale depth map of the scene is produced. We present results over multiple real underwater images and over a controlled test set where the target distance and true colors are known.},
	eventtitle = {{OCEANS} 2010 {MTS}/{IEEE} {SEATTLE}},
	pages = {1--8},
	booktitle = {{OCEANS} 2010 {MTS}/{IEEE} {SEATTLE}},
	author = {Carlevaris-Bianco, Nicholas and Mohan, Anush and Eustice, Ryan M.},
	urldate = {2025-06-09},
	date = {2010-09},
	note = {{ISSN}: 0197-7385},
	keywords = {Attenuation, Image color analysis, Atmospheric modeling, Estimation, Pixel, Scattering, Wheels},
	annotation = {Carlevaris-Bianco, Mohan, and Eustice propose the Maximum Intensity Prior ({MIP}), which uses the difference between channel maximums to determine scene depth. Their model exploits the asymmetric attenuation of light in water, such that the difference between red and other channels increases with distance. They refine their transmission map estimates with Markov random fields.
},
	file = {Full Text PDF:/home/user/Zotero/storage/DVVEVURQ/Carlevaris-Bianco \textit{et al.} - 2010 - Initial results in underwater single image dehazing.pdf:application/pdf},
}

@inproceedings{mcglamery_computer_1980,
	title = {A Computer Model For Underwater Camera Systems},
	volume = {0208},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/0208/0000/A-Computer-Model-For-Underwater-Camera-Systems/10.1117/12.958279.full},
	doi = {10.1117/12.958279},
	abstract = {A computer model is presented which allows the image components of an underwater camera system to be computed. Input parameters to the model are system geometry, source properties, and water optical properties. Output products are the irradiances due to non scattered object light, scattered object light and backscattered light. From these basic quantities other useful parameters such as contrast transmittances and signal to noise ratio can be calculated over the entire field of view of the camera. Sample calculations are presented.},
	eventtitle = {Ocean Optics {VI}},
	pages = {221--231},
	booktitle = {Ocean Optics {VI}},
	publisher = {{SPIE}},
	author = {{McGlamery}, B. L.},
	urldate = {2025-06-15},
	date = {1980-03-26},
	annotation = {{McGlamery} proposes an initial Image Formation Model ({IFM}) for underwater imaging, to be expanded on in \cite{jaffe_computer_1990}.
},
}

@article{jaffe_computer_1990,
	title = {Computer modeling and the design of optimal underwater imaging systems},
	volume = {15},
	issn = {1558-1691},
	url = {https://ieeexplore.ieee.org/abstract/document/50695},
	doi = {10.1109/48.50695},
	abstract = {A computer model to simulate the formation of underwater images has been developed. The model incorporates the inherent and apparent properties of the propagation of light in water. An image is approximated as a linear superposition of several image components. The model has been used to simulate the relative advantages of different camera/light configurations. The results indicate that extremely large gains in image contrast can be obtained by careful design of beam patterns and the manipulation of camera and light locations. The performance of range-gated systems is explored, and it is demonstrated that these systems are presently power limited. In order to obtain better quality images at larger distances, an imaging configuration which consists of scanning an incoherent light beam across the field of view of a camera is proposed. The incoherent light-scanning system is shown to have advantages over both conventional imaging techniques and range-gated methods.},
	pages = {101--111},
	number = {2},
	journaltitle = {{IEEE} Journal of Oceanic Engineering},
	author = {Jaffe, J.S.},
	urldate = {2025-06-15},
	date = {1990-04},
	keywords = {Cameras, Light scattering, Oceans, Optical attenuators, Optical computing, Optical imaging, Optical scattering, Quantum computing, Sea measurements, Water},
	annotation = {Jaffe fully specifies the {IFM} proposed in \cite{mcglamery_computer_1980}, holding total irradiance to be a combination of direct light (usually signal), and forward and backward scattering (usually noise): $E_T=E_d+E_{fs}+E_{bs}$. His model is simplified in \cite{schechner_clear_2004}.
},
}

@inproceedings{schechner_clear_2004,
	title = {Clear underwater vision},
	volume = {1},
	url = {https://ieeexplore.ieee.org/abstract/document/1315078},
	doi = {10.1109/CVPR.2004.1315078},
	abstract = {Underwater imaging is important for scientific research and technology, as well as for popular activities. We present a computer vision approach which easily removes degradation effects in underwater vision. We analyze the physical effects of visibility degradation. We show that the main degradation effects can be associated with partial polarization of light. We therefore present an algorithm which inverts the image formation process, to recover a good visibility image of the object. The algorithm is based on a couple of images taken through a polarizer at different orientations. As a by product, a distance map of the scene is derived as well. We successfully used our approach when experimenting in the sea using a system we built. We obtained great improvement of scene contrast and color correction, and nearly doubled the underwater visibility range.},
	eventtitle = {the 2004 {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition, 2004. {CVPR} 2004.},
	pages = {I--I},
	booktitle = {Proceedings of the 2004 {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition, 2004. {CVPR} 2004.},
	author = {Schechner, Y.Y. and Karpel, N.},
	urldate = {2025-06-15},
	date = {2004-06},
	note = {{ISSN}: 1063-6919},
	keywords = {Application software, Color, Computer vision, Degradation, Inspection, Layout, Lighting, Optical polarization, Underwater cables, Underwater tracking},
	annotation = {Schechner and Karpel propose a simplification of the Jaffe-{McGlamery} {IFM} (Jaffe, 1990) which ignores forward scattering. Each image channel is therefore $I^C(x)=J^C(x)t(x)+A^C(1-t(x))$, where $I^C$ is the image, $J$ is the ground truth, $A$ is the airlight, and $t$ is the transmission map. $t$ is further defined to be $t(x)=\exp(-\beta d(x))$ (albeit with difference naming conventions), where $\beta$ is the relevant attenuation coefficient and $d(x)$ is the scene depth for pixel $x$.
},
	file = {Submitted Version:/home/user/Zotero/storage/BQIZK8JL/Schechner and Karpel - 2004 - Clear underwater vision.pdf:application/pdf},
}

@inproceedings{he_single_2009,
	title = {Single image haze removal using dark channel prior},
	url = {https://ieeexplore.ieee.org/document/5206515},
	doi = {10.1109/CVPR.2009.5206515},
	abstract = {In this paper, we propose a simple but effective image prior - dark channel prior to remove haze from a single input image. The dark channel prior is a kind of statistics of the haze-free outdoor images. It is based on a key observation - most local patches in haze-free outdoor images contain some pixels which have very low intensities in at least one color channel. Using this prior with the haze imaging model, we can directly estimate the thickness of the haze and recover a high quality haze-free image. Results on a variety of outdoor haze images demonstrate the power of the proposed prior. Moreover, a high quality depth map can also be obtained as a by-product of haze removal.},
	eventtitle = {2009 {IEEE} Conference on Computer Vision and Pattern Recognition},
	pages = {1956--1963},
	booktitle = {2009 {IEEE} Conference on Computer Vision and Pattern Recognition},
	author = {He, Kaiming and Sun, Jian and Tang, Xiaoou},
	urldate = {2025-06-15},
	date = {2009-06},
	note = {{ISSN}: 1063-6919},
	keywords = {Pixel, Statistics},
	annotation = {He, Sun, and Tang propose the Dark Channel Prior ({DCP}) for surface image dehazing. Their prior assumes that at least one channel of every local block in a haze-free image will have some low intensity pixels, from which the transmission map $t(x)$ and airlight $A$ (described in \cite{schechner_clear_2004}) may be estimated.
},
}

@inproceedings{drews_jr_transmission_2013,
	title = {Transmission Estimation in Underwater Single Images},
	url = {https://ieeexplore.ieee.org/document/6755982},
	doi = {10.1109/ICCVW.2013.113},
	abstract = {This paper proposes a methodology to estimate the transmission in underwater environments which consists on an adaptation of the Dark Channel Prior ({DCP}), a statistical prior based on properties of images obtained in outdoor natural scenes. Our methodology, called Underwater {DCP} ({UDCP}), basically considers that the blue and green color channels are the underwater visual information source, which enables a significant improvement over existing methods based in {DCP}. This is shown through a comparative study with state of the art techniques, we present a detailed analysis of our technique which shows its applicability and limitations in images acquired from real and simulated scenes.},
	eventtitle = {2013 {IEEE} International Conference on Computer Vision Workshops},
	pages = {825--830},
	booktitle = {2013 {IEEE} International Conference on Computer Vision Workshops},
	author = {Drews, Paulo and Nascimento, Erickson R. and Moraes, F. and Botelho, Silvia S.C. and Montenegro Campos, Mario Fernando},
	urldate = {2025-06-15},
	date = {2013-12},
	keywords = {Absorption, Cameras, Channel estimation, Estimation, Image color analysis, Image restoration, Standards},
	annotation = {Drews \textit{et al.} propose the Underwater Dark Channel Prior ({UDCP}), an adaptation of {DCP} \cite{he_single_2009} to underwater images. They account for uneven light attenuation in underwater images essentially by ignoring the red channel.
},
}

@article{drews_underwater_2016,
	title = {Underwater Depth Estimation and Image Restoration Based on Single Images},
	volume = {36},
	issn = {1558-1756},
	url = {https://ieeexplore.ieee.org/document/7426236},
	doi = {10.1109/MCG.2016.26},
	abstract = {In underwater environments, the scattering and absorption phenomena affect the propagation of light, degrading the quality of captured images. In this work, the authors present a method based on a physical model of light propagation that takes into account the most significant effects to image degradation: absorption, scattering, and backscattering. The proposed method uses statistical priors to restore the visual quality of the images acquired in typical underwater scenarios.},
	pages = {24--35},
	number = {2},
	journaltitle = {{IEEE} Computer Graphics and Applications},
	author = {Drews, Paulo and Nascimento, Erickson R. and Botelho, Silvia S.C. and Montenegro Campos, Mario Fernando},
	urldate = {2025-06-15},
	date = {2016-03},
	keywords = {Absorption, Attenuation, backscattering, computer graphics, Dark Channel Prior, Image color analysis, image restoration, Image restoration, Scattering, Underwater Dark Channel Prior, underwater images, Visual computing},
	annotation = {Drews \textit{et al.} improve upon and test {UDCP} \cite{drews_jr_transmission_2013} experimentally.
},
}

@article{lisani_dehazing_2024,
	title = {Dehazing with Dark Channel Prior: Analysis and Implementation},
	volume = {14},
	issn = {2105-1232},
	url = {https://www.ipol.im/pub/art/2024/530/},
	doi = {10.5201/ipol.2024.530},
	shorttitle = {Dehazing with Dark Channel Prior},
	abstract = {In outdoor scenes, atmospheric absortion and scattering attenuate the radiance received by the camera and may produce haze. In 2009 He \textit{et al.} proposed a simple but effective dehazing algorithm based on a hypothesis called the 'dark channel prior' ({DCP}). Based on this prior several other dehazing methods have been published in recent years. In this paper we review the original algorithm by He et al, together with some posterior improvements proposed by the same and other authors. We also analyze the effect of the parameters on the results and we study a variant of the method proposed by Drews \textit{et al.} for the analysis of haze in underwater images.},
	pages = {173--193},
	journaltitle = {Image Processing On Line},
	author = {Lisani, Jose-Luis and Hessel, Charles},
	urldate = {2025-06-15},
	date = {2024-06-24},
	langid = {english},
	annotation = {Lisani and Hessel summarize the geneology of the Dark Channel Prior and provide an single-threaded implementation of it in C. Their implementation includes several parameters to modify the behavior of the algorithm, including for enabling {UDCP}.
},
	file = {Full Text PDF:/home/user/Zotero/storage/9IGF3FEY/Lisani and Hessel - 2024 - Dehazing with Dark Channel Prior Analysis and Implementation.pdf:application/pdf},
}

@article{li_enhancement_2023,
	title = {Enhancement and Optimization of Underwater Images and Videos Mapping},
	volume = {23},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/23/12/5708},
	doi = {10.3390/s23125708},
	abstract = {Underwater images tend to suffer from critical quality degradation, such as poor visibility, contrast reduction, and color deviation by virtue of the light absorption and scattering in water media. It is a challenging problem for these images to enhance visibility, improve contrast, and eliminate color cast. This paper proposes an effective and high-speed enhancement and restoration method based on the dark channel prior ({DCP}) for underwater images and video. Firstly, an improved background light ({BL}) estimation method is proposed to estimate {BL} accurately. Secondly, the R channel’s transmission map ({TM}) based on the {DCP} is estimated sketchily, and a {TM} optimizer integrating the scene depth map and the adaptive saturation map ({ASM}) is designed to refine the afore-mentioned coarse {TM}. Later, the {TMs} of G–B channels are computed by their ratio to the attenuation coefficient of the red channel. Finally, an improved color correction algorithm is adopted to improve visibility and brightness. Several typical image-quality assessment indexes are employed to testify that the proposed method can restore underwater low-quality images more effectively than other advanced methods. An underwater video real-time measurement is also conducted on the flipper-propelled underwater vehicle-manipulator system to verify the effectiveness of the proposed method in the real scene.},
	pages = {5708},
	number = {12},
	journaltitle = {Sensors},
	author = {Li, Chengda and Dong, Xiang and Wang, Yu and Wang, Shuo},
	urldate = {2025-06-15},
	date = {2023-01},
	langid = {english},
	note = {Number: 12
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {color correction, saturation map, transmission map optimizer, underwater image and video restoration},
	annotation = {Li \textit{et al.} propose a pipline based on {DCP} which uses different background light estimation formulas depending on detected attenuation severity, and which includes a novel transmission map optimization step.
},
	file = {Full Text PDF:/home/user/Zotero/storage/KI8A5MDQ/Li \textit{et al.} - 2023 - Enhancement and Optimization of Underwater Images and Videos Mapping.pdf:application/pdf},
}

@article{song_enhancement_2020,
	title = {Enhancement of Underwater Images With Statistical Model of Background Light and Optimization of Transmission Map},
	volume = {66},
	issn = {1557-9611},
	url = {https://ieeexplore.ieee.org/abstract/document/8957276},
	doi = {10.1109/TBC.2019.2960942},
	abstract = {Underwater images often have severe quality degradation and distortion due to light absorption and scattering in the water medium. A hazy image formation model is widely used to restore the image quality. It depends on two optical parameters: the background light ({BL}) and the transmission map ({TM}). Underwater images can also be enhanced by color and contrast correction from the perspective of image processing. In this paper, we propose an effective underwater image enhancement method for underwater images in composition of underwater image restoration and color correction. Firstly, a manually annotated background lights ({MABLs}) database is developed. With reference to the relationship between {MABLs} and the histogram distributions of various underwater images, robust statistical models of {BLs} estimation are provided. Next, the {TM} of R channel is roughly estimated based on the new underwater dark channel prior ({NUDCP}) via the statistic of clear and high resolution ({HD}) underwater images, then a scene depth map based on the underwater light attenuation prior ({ULAP}) and an adjusted reversed saturation map ({ARSM}) are applied to compensate and modify the coarse {TM} of R channel. Next, {TMs} of G-B channels are estimated based on the difference of attenuation ratios between R and G-B channels. Finally, to improve the color and contrast of the restored image with a dehazed and natural appearance, a variation of white balance is introduced as post-processing. In order to guide the priority of underwater image enhancement, sufficient evaluations are conducted to discuss the impacts of the key parameters including {BL} and {TM}, and the importance of the color correction. Comparisons with other state-of-the-art methods demonstrate that our proposed underwater image enhancement method can achieve higher accuracy of estimated {BLs}, lower computation time, overall superior performance, and better information retention.},
	pages = {153--169},
	number = {1},
	journaltitle = {{IEEE} Transactions on Broadcasting},
	author = {Song, Wei and Wang, Yan and Huang, Dongmei and Liotta, Antonio and Perra, Cristian},
	urldate = {2025-06-15},
	date = {2020-03},
	keywords = {Attenuation, Channel estimation, color improvement, Databases, Estimation, Image color analysis, Image enhancement, image quality, image restoration, Image restoration, Quality of experience, statistical model of background light, transmission map optimizer, underwater image enhancement},
	annotation = {Song \textit{et al.} propose a dehazing pipeline based on {UDCP}. They devel database of annotated background lights from which they derive statistical models for estimating {BL}. They refine the transmission map using {ULAP} \cite{song_rapid_2018}.
},
	file = {Submitted Version:/home/user/Zotero/storage/PNSFFE46/Song \textit{et al.} - 2020 - Enhancement of Underwater Images With Statistical Model of Background Light and Optimization of Tran.pdf:application/pdf},
}

@article{galdran_automatic_2015,
	title = {Automatic Red-Channel underwater image restoration},
	volume = {26},
	issn = {1047-3203},
	url = {https://www.sciencedirect.com/science/article/pii/S1047320314001874},
	doi = {10.1016/j.jvcir.2014.11.006},
	abstract = {Underwater images typically exhibit color distortion and low contrast as a result of the exponential decay that light suffers as it travels. Moreover, colors associated to different wavelengths have different attenuation rates, being the red wavelength the one that attenuates the fastest. To restore underwater images, we propose a Red Channel method, where colors associated to short wavelengths are recovered, as expected for underwater images, leading to a recovery of the lost contrast. The Red Channel method can be interpreted as a variant of the Dark Channel method used for images degraded by the atmosphere when exposed to haze. Experimental results show that our technique handles gracefully artificially illuminated areas, and achieves a natural color correction and superior or equivalent visibility improvement when compared to other state-of-the-art methods.},
	pages = {132--145},
	journaltitle = {Journal of Visual Communication and Image Representation},
	shortjournal = {Journal of Visual Communication and Image Representation},
	author = {Galdran, Adrian and Pardo, David and Picón, Artzai and Alvarez-Gila, Aitor},
	urldate = {2025-06-15},
	date = {2015-01-01},
	keywords = {Artificial lighting, Attenuation, Color correction, Contrast enhancement, Dark Channel, Image dehazing, Underwater image degradation, Underwater image restoration, Visibility recovery},
	annotation = {Galdran \textit{et al.} propose the Red Channel Prior ({RCP}), a variant of {DCP} which attempts to restore attenuated red channel information before dehazing. They claim their prior handles artificial illumination well.
},
	file = {Accepted Version:/home/user/Zotero/storage/RNQF67CZ/Galdran \textit{et al.} - 2015 - Automatic Red-Channel underwater image restoration.pdf:application/pdf},
}

@inproceedings{li_single_2016,
	title = {Single underwater image restoration by blue-green channels dehazing and red channel correction},
	url = {https://ieeexplore.ieee.org/abstract/document/7471973},
	doi = {10.1109/ICASSP.2016.7471973},
	abstract = {Restoring underwater image from a single image is know to be ill-posed, and some assumptions made in previous methods are not suitable for many situations. In this paper, we propose a method based on blue-green channels dehazing and red channel correction for underwater image restoration. Firstly, blue-green channels are recovered via dehazing algorithm based on an extension and modification of Dark Channel Prior algorithm. Then, red channel is corrected following the Gray-World assumption theory. Finally, in order to resolve the problem which some recovered image regions may look too dim or too bright, an adaptive exposure map is built. Qualitative analysis demonstrates that our method significantly improves visibility and contrast, and reduces the effects of light absorption and scattering. For quantitative analysis, our results obtain best values in terms of entropy, local feature points and average gradient, which outperform three existing physical model available methods.},
	eventtitle = {2016 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
	pages = {1731--1735},
	booktitle = {2016 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
	author = {Li, Chongyi and Quo, Jichang and Pang, Yanwei and Chen, Shanji and Wang, Jian},
	urldate = {2025-06-15},
	date = {2016-03},
	note = {{ISSN}: 2379-190X},
	keywords = {Absorption, Attenuation, Entropy, Image color analysis, image de-hazing, image enhancement, Image restoration, Imaging, Scattering, Underwater image restoration, visibility recovery},
	annotation = {Li \textit{et al.} propose an underwater dehazing pipeline which determines airlight and the transmission map with {MIP} \cite{carlevaris-bianco_initial_2010} and {DCP}, from which they dehaze the green and blue channels. They then use the Gray World Prior ({GW})—a trivial prior holding that the average intensity in any channel is 50\%—to correct attenuation in the red channel before dehazing it.
},
}

@article{he_guided_2013,
	title = {Guided Image Filtering},
	volume = {35},
	issn = {1939-3539},
	url = {https://ieeexplore.ieee.org/abstract/document/6319316/authors},
	doi = {10.1109/TPAMI.2012.213},
	abstract = {In this paper, we propose a novel explicit image filter called guided filter. Derived from a local linear model, the guided filter computes the filtering output by considering the content of a guidance image, which can be the input image itself or another different image. The guided filter can be used as an edge-preserving smoothing operator like the popular bilateral filter [1], but it has better behaviors near edges. The guided filter is also a more generic concept beyond smoothing: It can transfer the structures of the guidance image to the filtering output, enabling new filtering applications like dehazing and guided feathering. Moreover, the guided filter naturally has a fast and nonapproximate linear time algorithm, regardless of the kernel size and the intensity range. Currently, it is one of the fastest edge-preserving filters. Experiments show that the guided filter is both effective and efficient in a great variety of computer vision and computer graphics applications, including edge-aware smoothing, detail enhancement, {HDR} compression, image matting/feathering, dehazing, joint upsampling, etc.},
	pages = {1397--1409},
	number = {6},
	journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {He, Kaiming and Sun, Jian and Tang, Xiaoou},
	urldate = {2025-06-15},
	date = {2013-06},
	keywords = {bilateral filter, Edge-preserving filtering, Histograms, Image edge detection, Jacobian matrices, Joints, Kernel, Laplace equations, linear time filtering, Smoothing methods},
	annotation = {He \textit{et al.} propose an image filter which smooths the output image without destroying edge information. Their filter is used by {IFM}-based pipelines to refine block-wise transmission maps.
},
}

@article{li_underwater_2015,
	title = {Underwater image enhancement by dehazing and color correction},
	volume = {24},
	issn = {1017-9909, 1560-229X},
	url = {https://www.spiedigitallibrary.org/journals/journal-of-electronic-imaging/volume-24/issue-3/033023/Underwater-image-enhancement-by-dehazing-and-color-correction/10.1117/1.JEI.24.3.033023.full},
	doi = {10.1117/1.JEI.24.3.033023},
	abstract = {Poor visibility due to the effects of light absorption and scattering is challenging for processing underwater images. We propose an approach based on dehazing and color correction algorithms for underwater image enhancement. First, a simple dehazing algorithm is applied to remove the effects of haze in the underwater image. Second, color compensation, histogram equalization, saturation, and intensity stretching are used to improve contrast, brightness, color, and visibility of the underwater image. Furthermore, bilateral filtering is utilized to address the problem of the noise caused by the physical properties of the medium and the histogram equalization algorithm. In order to evaluate the performance of the proposed approach, we compared our results with six existing methods using the subjective technique, objective technique, and color cast tests. The results show that the proposed approach outperforms the six existing methods. The enhanced images, as a result of implementing the proposed approach, are characterized by relatively genuine color, increased contrast and brightness, reduced noise level, and better visibility.},
	pages = {033023},
	number = {3},
	journaltitle = {Journal of Electronic Imaging},
	shortjournal = {{JEI}},
	author = {Li, Chongyi and Guo, Jichang},
	urldate = {2025-06-15},
	date = {2015-06},
	note = {Publisher: {SPIE}},
	annotation = {Li and Guo propose an underwater dehazing pipeline based on a simplified {MIP} \cite{carlevaris-bianco_initial_2010}. They also process their images with a series of traditional techniques, including histogram equalization, color compensation, and bilateral filtering. Their pipeline focuses on color correction.
},
}

@inproceedings{berman_non-local_2016,
	title = {Non-local Image Dehazing},
	url = {https://ieeexplore.ieee.org/document/7780554},
	doi = {10.1109/CVPR.2016.185},
	abstract = {Haze limits visibility and reduces image contrast in outdoor images. The degradation is different for every pixel and depends on the distance of the scene point from the camera. This dependency is expressed in the transmission coefficients, that control the scene attenuation and amount of haze in every pixel. Previous methods solve the single image dehazing problem using various patch-based priors. We, on the other hand, propose an algorithm based on a new, non-local prior. The algorithm relies on the assumption that colors of a haze-free image are well approximated by a few hundred distinct colors, that form tight clusters in {RGB} space. Our key observation is that pixels in a given cluster are often non-local, i.e., they are spread over the entire image plane and are located at different distances from the camera. In the presence of haze these varying distances translate to different transmission coefficients. Therefore, each color cluster in the clear image becomes a line in {RGB} space, that we term a haze-line. Using these haze-lines, our algorithm recovers both the distance map and the haze-free image. The algorithm is linear in the size of the image, deterministic and requires no training. It performs well on a wide variety of images and is competitive with other stateof-the-art methods.},
	eventtitle = {2016 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	pages = {1674--1682},
	booktitle = {2016 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	author = {Berman, Dana and Treibitz, Tali and Avidan, Shai},
	urldate = {2025-06-15},
	date = {2016-06},
	note = {{ISSN}: 1063-6919},
	keywords = {Atmospheric modeling, Cameras, Clustering algorithms, Histograms, Image color analysis, Image segmentation, Quantization (signal)},
	annotation = {Berman, Treibitz, and Avidan propose the Haze-Lines Prior ({HLP}) for dehazing surface images. Their prior uses non-local information about similarly colored groups of pixels to construct ``haze lines''' in the image’s color space. In hazy images, these lines intersect at the airlight color. {HLP} therefore does not suffer from the same risks that local (e.g. quadtrees-based) airlight estimation does.
},
}

@article{berman_underwater_2021,
	title = {Underwater Single Image Color Restoration Using Haze-Lines and a New Quantitative Dataset},
	volume = {43},
	issn = {1939-3539},
	url = {https://ieeexplore.ieee.org/document/9020130},
	doi = {10.1109/TPAMI.2020.2977624},
	abstract = {Underwater images suffer from color distortion and low contrast, because light is attenuated while it propagates through water. Attenuation under water varies with wavelength, unlike terrestrial images where attenuation is assumed to be spectrally uniform. The attenuation depends both on the water body and the 3D structure of the scene, making color restoration difficult. Unlike existing single underwater image enhancement techniques, our method takes into account multiple spectral profiles of different water types. By estimating just two additional global parameters: the attenuation ratios of the blue-red and blue-green color channels, the problem is reduced to single image dehazing, where all color channels have the same attenuation coefficients. Since the water type is unknown, we evaluate different parameters out of an existing library of water types. Each type leads to a different restored image and the best result is automatically chosen based on color distribution. We also contribute a dataset of 57 images taken in different locations. To obtain ground truth, we placed multiple color charts in the scenes and calculated its 3D structure using stereo imaging. This dataset enables a rigorous quantitative evaluation of restoration algorithms on natural images for the first time.},
	pages = {2822--2837},
	number = {8},
	journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Berman, Dana and Levy, Deborah and Avidan, Shai and Treibitz, Tali},
	urldate = {2025-06-15},
	date = {2021-08},
	keywords = {Attenuation, Cameras, Channel estimation, computational photography, image color analysis, Image color analysis, image enhancement, Image processing and computer vision, image restoration, Image restoration, Optical attenuators, Three-dimensional displays},
	annotation = {Berman, \textit{et al.} extend {HLP} \cite{berman_non-local_2016} for underwater use. They develop a database of Jerlov optical water types and their attenuation coefficients. For a given underwater image, they then estimate blue vs. red and blue vs. green channel attenuation ratios and compare them to their database to find attenuation coefficients, reverse channel attenuation, and dehaze the image as if it were taken in air.
},
	file = {Submitted Version:/home/user/Zotero/storage/WICWP3JT/Berman \textit{et al.} - 2021 - Underwater Single Image Color Restoration Using Haze-Lines and a New Quantitative Dataset.pdf:application/pdf},
}

@article{peng_underwater_2017,
	title = {Underwater Image Restoration Based on Image Blurriness and Light Absorption},
	volume = {26},
	issn = {1941-0042},
	url = {https://ieeexplore.ieee.org/document/7840002},
	doi = {10.1109/TIP.2017.2663846},
	abstract = {Underwater images often suffer from color distortion and low contrast, because light is scattered and absorbed when traveling through water. Such images with different color tones can be shot in various lighting conditions, making restoration and enhancement difficult. We propose a depth estimation method for underwater scenes based on image blurriness and light absorption, which can be used in the image formation model ({IFM}) to restore and enhance underwater images. Previous {IFM}-based image restoration methods estimate scene depth based on the dark channel prior or the maximum intensity prior. These are frequently invalidated by the lighting conditions in underwater images, leading to poor restoration results. The proposed method estimates underwater scene depth more accurately. Experimental results on restoring real and synthesized underwater images demonstrate that the proposed method outperforms other {IFM}-based underwater image restoration methods.},
	pages = {1579--1594},
	number = {4},
	journaltitle = {{IEEE} Transactions on Image Processing},
	author = {Peng, Yan-Tsung and Cosman, Pamela C.},
	urldate = {2025-06-15},
	date = {2017-04},
	keywords = {Absorption, blurriness, Cameras, Channel estimation, depth estimation, Estimation, Image color analysis, image enhancement, image restoration, Image restoration, light absorption, Lighting, Underwater image},
	annotation = {Peng and Cosman propose the Image Blurriness and Light Absorption Prior ({BLAP}), which uses local blurriness and estimates of light absorption to estimate airlight and the transmission map, with the goal of decreasing sensitivity to lighting conditions. Their method is computationally expensive. They also tabulate the {BL} and {TM} equations of several other priors.
},
	file = {Full Text:/home/user/Zotero/storage/HDCU67E2/Peng and Cosman - 2017 - Underwater Image Restoration Based on Image Blurriness and Light Absorption.pdf:application/pdf},
}

@article{li_underwater_2020,
	title = {An Underwater Image Enhancement Benchmark Dataset and Beyond},
	volume = {29},
	issn = {1941-0042},
	url = {https://ieeexplore.ieee.org/document/8917818},
	doi = {10.1109/TIP.2019.2955241},
	abstract = {Underwater image enhancement has been attracting much attention due to its significance in marine engineering and aquatic robotics. Numerous underwater image enhancement algorithms have been proposed in the last few years. However, these algorithms are mainly evaluated using either synthetic datasets or few selected real-world images. It is thus unclear how these algorithms would perform on images acquired in the wild and how we could gauge the progress in the field. To bridge this gap, we present the first comprehensive perceptual study and analysis of underwater image enhancement using large-scale real-world images. In this paper, we construct an Underwater Image Enhancement Benchmark ({UIEB}) including 950 real-world underwater images, 890 of which have the corresponding reference images. We treat the rest 60 underwater images which cannot obtain satisfactory reference images as challenging data. Using this dataset, we conduct a comprehensive study of the state-of-the-art underwater image enhancement algorithms qualitatively and quantitatively. In addition, we propose an underwater image enhancement network (called Water-Net) trained on this benchmark as a baseline, which indicates the generalization of the proposed {UIEB} for training Convolutional Neural Networks ({CNNs}). The benchmark evaluations and the proposed Water-Net demonstrate the performance and limitations of state-of-the-art algorithms, which shed light on future research in underwater image enhancement. The dataset and code are available at https://li-chongyi.github.io/proj_benchmark.html.},
	pages = {4376--4389},
	journaltitle = {{IEEE} Transactions on Image Processing},
	author = {Li, Chongyi and Guo, Chunle and Ren, Wenqi and Cong, Runmin and Hou, Junhui and Kwong, Sam and Tao, Dacheng},
	urldate = {2025-06-15},
	date = {2020},
	keywords = {comprehensive evaluation, Convolutional neural networks, deep learning, Deep learning, Image enhancement, Image restoration, Object detection, real-world underwater images, Statistical analysis, Underwater image enhancement, Underwater technology},
	annotation = {Li \textit{et al.} propose the {WaterNet} {CNN} trained on their novel Underwater Image Enhancement Benchmark dataset. The dataset contains 890 referenced and 60 referenceless images.
},
	file = {Submitted Version:/home/user/Zotero/storage/678TLEV4/Li \textit{et al.} - 2020 - An Underwater Image Enhancement Benchmark Dataset and Beyond.pdf:application/pdf},
}

@article{li_underwater_2020-1,
	title = {Underwater scene prior inspired deep underwater image and video enhancement},
	volume = {98},
	issn = {0031-3203},
	url = {https://www.sciencedirect.com/science/article/pii/S0031320319303401},
	doi = {10.1016/j.patcog.2019.107038},
	abstract = {In underwater scenes, wavelength-dependent light absorption and scattering degrade the visibility of images and videos. The degraded underwater images and videos affect the accuracy of pattern recognition, visual understanding, and key feature extraction in underwater scenes. In this paper, we propose an underwater image enhancement convolutional neural network ({CNN}) model based on underwater scene prior, called {UWCNN}. Instead of estimating the parameters of underwater imaging model, the proposed {UWCNN} model directly reconstructs the clear latent underwater image, which benefits from the underwater scene prior which can be used to synthesize underwater image training data. Besides, based on the light-weight network structure and effective training data, our {UWCNN} model can be easily extended to underwater videos for frame-by-frame enhancement. Specifically, combining an underwater imaging physical model with optical properties of underwater scenes, we first synthesize underwater image degradation datasets which cover a diverse set of water types and degradation levels. Then, a light-weight {CNN} model is designed for enhancing each underwater scene type, which is trained by the corresponding training data. At last, this {UWCNN} model is directly extended to underwater video enhancement. Experiments on real-world and synthetic underwater images and videos demonstrate that our method generalizes well to different underwater scenes.},
	pages = {107038},
	journaltitle = {Pattern Recognition},
	shortjournal = {Pattern Recognition},
	author = {Li, Chongyi and Anwar, Saeed and Porikli, Fatih},
	urldate = {2025-06-15},
	date = {2020-02-01},
	keywords = {Deep learning, Pattern recognition, Underwater image and video enhancement and restoration, Underwater image synthesis},
	annotation = {Li, Anwar and Porikli propose {UWCNN}, a shallow {CNN} for underwater dehazing. The claim their model achieves 2.25 second per-frame runtimes on the {CPU}, and 0.225 on the {GPUs}. They extend their model to maintain consistent coloring between frames.
},
}

@article{wang_uiec2-net_2021,
	title = {{UIEC}{\textasciicircum}2-Net: {CNN}-based underwater image enhancement using two color space},
	volume = {96},
	issn = {0923-5965},
	url = {https://www.sciencedirect.com/science/article/pii/S0923596521001004},
	doi = {10.1016/j.image.2021.116250},
	shorttitle = {{UIEC}{\textasciicircum}2-Net},
	abstract = {Underwater image enhancement has attracted much attention due to the rise of marine resource development in recent years. Benefit from the powerful representation capabilities of Convolution Neural Networks({CNNs}), multiple underwater image enhancement algorithms based on {CNNs} have been proposed in the past few years. However, almost all of these algorithms employ {RGB} color space setting, which is insensitive to image properties such as luminance and saturation. To address this problem, we proposed Underwater Image Enhancement Convolution Neural Network using 2 Color Space ({UICE}{\textasciicircum}2-Net) that efficiently and effectively integrate both {RGB} Color Space and {HSV} Color Space in one single {CNN}. To our best knowledge, this method is the first one to use {HSV} color space for underwater image enhancement based on deep learning. {UIEC}{\textasciicircum}2-Net is an end-to-end trainable network, consisting of three blocks as follow: a {RGB} pixel-level block implements fundamental operations such as denoising and removing color cast, a {HSV} global-adjust block for globally adjusting underwater image luminance, color and saturation by adopting a novel neural curve layer, and an attention map block for combining the advantages of {RGB} and {HSV} block output images by distributing weight to each pixel. Experimental results on synthetic and real-world underwater images show that the proposed method has good performance in both subjective comparisons and objective metrics. The code is available at https://github.com/{BIGWangYuDong}/{UWEnhancement}.},
	pages = {116250},
	journaltitle = {Signal Processing: Image Communication},
	shortjournal = {Signal Processing: Image Communication},
	author = {Wang, Yudong and Guo, Jichang and Gao, Huan and Yue, Huihui},
	urldate = {2025-06-15},
	date = {2021-08-01},
	keywords = {Deep learning, {HSV} color space, Underwater image enhancement},
	annotation = {Wang \textit{et al.} propose the {UIEC}{\textasciicircum}2-Net {CNN} for dehazing underwater images. Their {CNN} processes underwater images in both {RGB} and {HSV} color spaces.
},
	file = {Submitted Version:/home/user/Zotero/storage/MM6AHL4J/Wang \textit{et al.} - 2021 - UIEC^2-Net CNN-based underwater image enhancement using two color space.pdf:application/pdf},
}

@article{qing_underwater_2016,
	title = {Underwater video dehazing based on spatial–temporal information fusion},
	volume = {27},
	issn = {1573-0824},
	url = {https://doi.org/10.1007/s11045-016-0407-2},
	doi = {10.1007/s11045-016-0407-2},
	abstract = {In this paper, a novel multidimensional underwater video dehazing method is presented to restore and enhance the underwater degraded videos. Videos in the underwater suffer from medium scattering and light absorption. The absorption of light traveling in the water makes the underwater hazing videos different from the atmosphere hazing videos. In order to dehaze the underwater videos, a spatial–temporal information fusion method is proposed which includes two main parts. One is transmission estimation, which is based on the correlation between the adjacent frames of videos to keep the color consistency, where fast tracking and the least square method are used to reduce the influence of camera and object motions and water flowing. Another part is background light estimation to keep consistent atmospheric light values in a video. Extensive experimental results demonstrate that the proposed algorithm can have superior haze removing and color balancing capabilities.},
	pages = {909--924},
	number = {4},
	journaltitle = {Multidimensional Systems and Signal Processing},
	shortjournal = {Multidim Syst Sign Process},
	author = {Qing, Chunmei and Yu, Feng and Xu, Xiangmin and Huang, Wenyou and Jin, Jianxiu},
	urldate = {2025-06-15},
	date = {2016-10-01},
	langid = {english},
	keywords = {Dark channel prior, Guided filter, Image Processing, Multimedia Information Systems, Multimedia Journalism, Optical cloaking, Spatial–temporal fusion, Time-lapse Imaging, Underwater Acoustics, Underwater video dehazing},
	annotation = {Qing \textit{et al.} propose a surface video dehazing pipeline which spreads {DCP} information across several frames using information fusion.
},
	file = {Full Text PDF:/home/user/Zotero/storage/JSEP6DJJ/Qing \textit{et al.} - 2016 - Underwater video dehazing based on spatial–temporal information fusion.pdf:application/pdf},
}

@article{kim_optimized_2013,
	title = {Optimized contrast enhancement for real-time image and video dehazing},
	volume = {24},
	issn = {1047-3203},
	url = {https://www.sciencedirect.com/science/article/pii/S1047320313000242},
	doi = {10.1016/j.jvcir.2013.02.004},
	abstract = {A fast and optimized dehazing algorithm for hazy images and videos is proposed in this work. Based on the observation that a hazy image exhibits low contrast in general, we restore the hazy image by enhancing its contrast. However, the overcompensation of the degraded contrast may truncate pixel values and cause information loss. Therefore, we formulate a cost function that consists of the contrast term and the information loss term. By minimizing the cost function, the proposed algorithm enhances the contrast and preserves the information optimally. Moreover, we extend the static image dehazing algorithm to real-time video dehazing. We reduce flickering artifacts in a dehazed video sequence by making transmission values temporally coherent. Experimental results show that the proposed algorithm effectively removes haze and is sufficiently fast for real-time dehazing applications.},
	pages = {410--425},
	number = {3},
	journaltitle = {Journal of Visual Communication and Image Representation},
	shortjournal = {Journal of Visual Communication and Image Representation},
	author = {Kim, Jin-Hwan and Jang, Won-Dong and Sim, Jae-Young and Kim, Chang-Su},
	urldate = {2025-06-15},
	date = {2013-04-01},
	keywords = {Atmospheric light estimation, Contrast enhancement, Image dehazing, Image enhancement, Image restoration, Optimized dehazing, Temporal coherence, Video dehazing},
	annotation = {Kim \textit{et al.} propose a model-based approach to surface image and video dehazing. They estimate airlight and the transmission map with bespoke priors. They claim their model achieves 7-8 {FPS} on a single thread, and 30-40 when multithreaded.
},
}

@article{alsakar_underwater_2025,
	title = {Underwater image restoration and enhancement: a comprehensive review of recent trends, challenges, and applications},
	volume = {41},
	issn = {1432-2315},
	url = {https://doi.org/10.1007/s00371-024-03630-w},
	doi = {10.1007/s00371-024-03630-w},
	shorttitle = {Underwater image restoration and enhancement},
	abstract = {In recent years, underwater exploration for deep-sea resource utilization and development has a considerable interest. In an underwater environment, the obtained images and videos undergo several quality degradations resulting from light absorption and scattering, low contrast, color deviation, blurred details, and nonuniform illumination. Therefore, the restoration and enhancement of degraded images and videos are critical. Numerous techniques of image processing, pattern recognition, and computer vision have been proposed for image restoration and enhancement, but many challenges remain. This survey has been estimated to be superior to other reviews because it collects all their shortcomings and lacks and gives researchers many ideas for the future. This survey presents a comparison of the most prominent approaches in underwater image processing and analysis. It also discusses an overview of the underwater environment with a broad classification into enhancement and restoration techniques and introduces the main underwater image degradation reasons in addition to the underwater image model. The existing underwater image analysis techniques, methods, datasets, and evaluation metrics are presented in detail. Furthermore, the existing limitations are analyzed, which are classified into image-related and environment-related categories. In addition, the performance is validated on images from the {UIEB} dataset for qualitative, quantitative, and computational time assessment. Areas in which underwater images have recently been applied are briefly discussed. Finally, recommendations for future research are provided and the conclusion is presented.},
	pages = {3735--3783},
	number = {6},
	journaltitle = {The Visual Computer},
	shortjournal = {Vis Comput},
	author = {Alsakar, Yasmin M. and Sakr, Nehal A. and El-Sappagh, Shaker and Abuhmed, Tamer and Elmogy, Mohammed},
	urldate = {2025-06-15},
	date = {2025-04-01},
	langid = {english},
	keywords = {3-D Image Reconstruction, Computer Imaging, Vision, Pattern Recognition and Graphics, Image Processing, Imaging Techniques, Ocean Sciences, Underwater Acoustics, Underwater datasets, Underwater image analysis, Underwater image enhancement, Underwater image quality evaluation, Underwater image restoration},
	annotation = {Alsakar \textit{et al.} review machine learning, model-based, and model-free methods for underwater dehazing. They also tabulate {CPU} runtimes for several algorithms.
},
	file = {Full Text PDF:/home/user/Zotero/storage/LYPQDX6G/Alsakar \textit{et al.} - 2025 - Underwater image restoration and enhancement a comprehensive review of recent trends, challenges, a.pdf:application/pdf},
}

@article{shuang_algorithms_2024,
	title = {Algorithms for improving the quality of underwater optical images: A comprehensive review},
	volume = {219},
	issn = {0165-1684},
	url = {https://www.sciencedirect.com/science/article/pii/S0165168424000276},
	doi = {10.1016/j.sigpro.2024.109408},
	shorttitle = {Algorithms for improving the quality of underwater optical images},
	abstract = {High-quality underwater optical images are essential for various applications of underwater vision. However, these images often suffer from severe degradation, complex noise, low contrast, and color cast, leading to poor image quality. To address these issues and accomplish related underwater vision tasks more smoothly, researchers have made many efforts to improve the quality of underwater optical images. This paper presents a comprehensive review of recent research, focusing on specific algorithms published between 2013 and 2023, while also predicting future research trends in this field. In light of the observed ambiguities and inconsistencies in previous review studies’ classification frameworks, this paper introduces a novel classification framework, grounded in the specific challenges in this domain, including issues unique to the imaging medium and imaging environment. Additionally, the proposed framework offers a more detailed categorization based on the algorithmic ideology of the authors. Furthermore, this paper addresses a significant gap in the literature by providing an in-depth assessment of the methods for removing marine snow noise from underwater optical images. By complementing existing research, this paper aims to enhance understanding of this subject and provide a clearer, more comprehensive, and in-depth exploration of underwater image quality improvement.},
	pages = {109408},
	journaltitle = {Signal Processing},
	shortjournal = {Signal Processing},
	author = {Shuang, Xuecheng and Zhang, Jin and Tian, Yu},
	urldate = {2025-06-15},
	date = {2024-06-01},
	keywords = {Image quality improvement, Light attenuation, Marine snow, Noise removal, Underwater optical images},
	annotation = {Shuang, Zhang, and Tian review machine learning, model-based, and model-free methods for underwater dehazing. They also discuss performance metrics and datasets with which to evaluate these models.
},
	file = {ScienceDirect Snapshot:/home/user/Zotero/storage/QYKV2AEA/S0165168424000276.html:text/html},
}

@inproceedings{song_rapid_2018,
	location = {Cham},
	title = {A Rapid Scene Depth Estimation Model Based on Underwater Light Attenuation Prior for Underwater Image Restoration},
	isbn = {978-3-030-00776-8},
	abstract = {Underwater images present blur and color cast, caused by light absorption and scattering in water medium. To restore underwater images through image formation model ({IFM}), the scene depth map is very important for the estimation of the transmission map and background light intensity. In this paper, we propose a rapid and effective scene depth estimation model based on underwater light attenuation prior ({ULAP}) for underwater images and train the model coefficients with learning-based supervised linear regression. With the correct depth map, the background light ({BL}) and transmission maps ({TMs}) for R-G-B light are easily estimated to recover the true scene radiance under the water. In order to evaluate the superiority of underwater image restoration using our estimated depth map, three assessment metrics demonstrate that our proposed method can enhance perceptual effect with less running time, compared to four state-of-the-art image restoration methods.},
	pages = {678--688},
	booktitle = {Advances in Multimedia Information Processing – {PCM} 2018},
	publisher = {Springer International Publishing},
	author = {Song, Wei and Wang, Yan and Huang, Dongmei and Tjondronegoro, Dian},
	editor = {Hong, Richang and Cheng, Wen-Huang and Yamasaki, Toshihiko and Wang, Meng and Ngo, Chong-Wah},
	date = {2018},
	annotation = {Wei \textit{et al.} propose the Underwater Light Attenuation Prior ({ULAP}), which defines depth at pixel $x$ to be $d(x)=\mu_0+\mu_1m(x)+\mu_2v(x)$, where $m(x)$ is $\max(I^G(x),I^B(x))$, and $v(x)$ is $I^R(x)$. They learn the coefficients $\mu$ with Pearson correlation analysis. They claim per-frame runtimes of less than a second.
},
}
